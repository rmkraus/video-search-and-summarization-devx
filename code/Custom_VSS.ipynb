{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13a84f0-840c-4a24-a936-e26a22285804",
   "metadata": {},
   "source": [
    "# Customizing VSS Blueprint\n",
    "\n",
    "In this exercise, we will create an agent to assist with bridge inspections. This agent will identify issues from drone footage detailing the condition of the bridge. Cosmetic issues should be differentiated from structural issues. Vandalism and landscaping issues should also be reported.\n",
    "\n",
    "**Remember:** For a quick reminder, go back and check [Intro_To_VSS.ipynb](Intro_To_VSS.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "But first, the standard imports, settings, and helpers from last exercise. To save space, we will import these functions from [helpers.py](helpers.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409cba2-2148-4775-8259-e593794c6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import helpers\n",
    "from IPython.display import Markdown, Video\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from typing import Literal, Any\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import wizards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fcb7a-5151-4b90-8e31-a4f73e7a2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths and locations\n",
    "VSS_URL = \"http://via-server:8100\"\n",
    "BRIDGE_VIDEO = Path(\"../assets/bridge.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34676f-eb80-407d-b979-eb6c5d0a9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for talking to the API\n",
    "from helpers import check_response, vss_api_call, Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51d447-a2bc-4ad4-82e4-dae751095796",
   "metadata": {},
   "source": [
    "## Inspect drone footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92a94a-cc4c-4aa6-8888-32106b70c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(BRIDGE_VIDEO, width=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48b02a-69e0-48ba-9408-0818a61bfe8b",
   "metadata": {},
   "source": [
    "## Query the available models\n",
    "\n",
    "Create a variable called `models_response` that is the list of the available models. \n",
    "\n",
    "<details>\n",
    "    <summary><b>ðŸ’¢ Stuck?</b></summary>\n",
    "\n",
    "```python\n",
    "models_response = vss_api_call(VSS_URL, \"models\")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c4111-1ab6-485c-aeb0-71975a75888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_response = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc4ac6-671b-43d6-8d38-02f8efe705a8",
   "metadata": {},
   "source": [
    "## Upload the video file\n",
    "\n",
    "In order for the blueprint to access the video file, we must first upload it. This is a simple post to the files API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb374d78-ac58-49d2-9d22-e00045f31795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with BRIDGE_VIDEO.open(\"rb\") as file:\n",
    "    # setup query data\n",
    "    files = {\"file\": (BRIDGE_VIDEO.name, file)}\n",
    "    data = {\"purpose\":\"vision\", \"media_type\":\"video\"}\n",
    "\n",
    "    # query the vss api\n",
    "    upload_response = vss_api_call(\n",
    "        VSS_URL,\n",
    "        \"files\",\n",
    "        verb=\"post\",\n",
    "        files=files,\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8250ac4-4659-4ba8-9e23-900a36a8f74f",
   "metadata": {},
   "source": [
    "## Customize Prompts\n",
    "\n",
    "We will also need tailored prompts. \n",
    "First, write a `prompt` that instructs the VLM what to look for.\n",
    "\n",
    "Remember, these usually have three parts:\n",
    "1. Persona\n",
    "2. Details\n",
    "3. Format\n",
    "\n",
    "<details>\n",
    "    <summary><b>ðŸ’¢ Stuck?</b></summary>\n",
    "\n",
    "```python\n",
    "prompt = (\n",
    "    \"You are a bridge inspector. \"\n",
    "    \"Describe any concerns you have with this bridge in detail. \"\n",
    "    \"Your concerns may be: \"\n",
    "    \"cosmetic, structural, landscaping, or vandalism in nature.\"\n",
    "    \"Start each event description with a start and end time stamp of the event.\"\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163c9fc-27f7-48a5-9a32-3a0d4593d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf17e94-6bd9-4f7d-a893-7c5d1703e763",
   "metadata": {},
   "source": [
    "Next we write the `caption_summarization_prompt`. This is the one that rarely changes, so we can start with the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299e8b1-25c2-4867-9fbd-31686c674923",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_summarization_prompt = (\n",
    "    \"If any descriptions have the same meaning and are sequential \"\n",
    "    \"then combine them under one sentence and merge the time stamps \"\n",
    "    \"to a range. Format the timestamps as 'mm:ss'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6830d34-0dc3-4776-bc1e-784a8c0366ca",
   "metadata": {},
   "source": [
    "Finally, the `summary_aggregation_prompt` that is used to generate the final summary. Best practice is for this to reiterate what details need to be included in the summary and any formatting options.\n",
    "\n",
    "<details>\n",
    "    <summary><b>ðŸ’¢ Stuck?</b></summary>\n",
    "\n",
    "```python\n",
    "summary_aggregation_prompt = (\n",
    "    \"Based on the available information, generate a report \"\n",
    "    \"that describes the condition of the bridge. The report \"\n",
    "    \"should be organized into cosmetic, structural, vegetation \"\n",
    "    \"overgrowth, and vandalism. The report must include timestamps. \"\n",
    "    \"This should be a concise, yet descriptive summary of all \"\n",
    "    \"the important events. The format should be intuitive and \"\n",
    "    \"easy for a user to understand what happened. Format the \"\n",
    "    \"output in Markdown so it can be displayed nicely.\"\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc89fe-2b76-47df-a63c-7bf83e3d334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_aggregation_prompt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab3070-7782-45a8-a1a3-9dcf79bcbf22",
   "metadata": {},
   "source": [
    "Everything is now in place to start some basic testing. Starting with basic parameters will be good enough to test the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd2f7f-e642-4d12-877e-a12510397f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"id\": upload_response.get(\"id\"), \n",
    "    \"prompt\": prompt,\n",
    "    \"caption_summarization_prompt\": caption_summarization_prompt,\n",
    "    \"summary_aggregation_prompt\": summary_aggregation_prompt,\n",
    "    \"model\": models_response[\"data\"][0][\"id\"],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.4,\n",
    "    \"top_p\": 1,\n",
    "    \"seed\": 1,\n",
    "    \"num_frames_per_chunk\": 10,\n",
    "    \"chunk_duration\": 30,\n",
    "    \"chunk_overlap_duration\": 0,\n",
    "    \"enable_chat\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40259415-23a1-4074-9734-8eee06b7b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_response = vss_api_call(VSS_URL, \"summarize\", verb=\"post\", json=body)\n",
    "print(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647bfda-920f-4428-86ee-97cf1396c167",
   "metadata": {},
   "source": [
    "How was that response? Does it to include the right kind of information? If so, then continue on to tuning aditional parameters. If not, revisit your prompts and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff386a05-130c-4d45-b30a-875b607b06b3",
   "metadata": {},
   "source": [
    "## Chunking Parameters\n",
    "\n",
    "The chunking strategies are very important to tune for each use case.\n",
    "\n",
    "![Chunking Diagram](../assets/chunk_duration.png)\n",
    "\n",
    "- `num_frames_per_chunk` controls how many still frames will be selected from each chunk for analysis. These frames are the input to the VLM for building an understanding of the video.\n",
    "\n",
    "- `chunk_overlap_duration` can also be added to the summarization request to configure overlap between chunks. This increases accuracy at chunk boundaries.\n",
    "\n",
    "- `chunk_duration` (also known as chunk size) is very important to tune based on the use case. The chunk size determines the temporal granularity at which the VLM will view the video.\n",
    "\n",
    "\n",
    "Longer chunks result in fewer frames being send to the VLM for analysis. \n",
    "This causes less granularity in your summaries. However, longer chunks increase the odds that important events happen away from chunk boundaries. They also decrease compute time.\n",
    "\n",
    "To understand how these parameters affect the final output, change the values in this widget. Find some that look good and run the next cell. How were the results impacted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f81e55-17f7-4196-a68c-c5066e123d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_frames_per_chunk, chunk_duration, chunk_overlap_duration) = \\\n",
    "    wizards.tune_chunks(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e97a33-e5fb-4198-a7b8-4a39bd09787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary with selected values\n",
    "summarize_response = vss_api_call(VSS_URL, \"summarize\", verb=\"post\", json=body)\n",
    "print(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6a9e8-6a9c-480e-a772-dc921e367f3d",
   "metadata": {},
   "source": [
    "Is that better or worse? The decision is up to you. If you wan't some advice, or just want to compare notes, check out these **hints**.\n",
    "\n",
    "<details>\n",
    "    <summary><b>HINTS</b></summary>\n",
    "\n",
    "    Using the recomended prompts and the starting settings, the fidelity of the results is already acceptable. Howver, the input video has hard breaks every 30 seconds. This causes very siloed responses. To accomodate this, while not increasing the fidelity more than necessary:\n",
    "    \n",
    "    - increase `chunk_duration_overlap` to 5 to overlap video boundaries\n",
    "    - increase `chunk_duration` to 35 to maintain 60 total frames\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8250f-a0dd-4c20-8453-d399de8da134",
   "metadata": {},
   "source": [
    "## Inference Time Model Tuning\n",
    "\n",
    "The summarize API also accepts parameters to control the LLM during summary generation. The important ones to note are:\n",
    "\n",
    "- `max_tokens` controls the maximum length of summary generation. This is a hard cutoff and does not change model output. Typically, `1024` is accetable, but smaller values could result in lower costs.\n",
    "- `temperature` and `top_p` parameters influence the probabilities when choosing the next output token. Generally, lower values tend towards more consistent, but less insightful, responses.\n",
    "- `seed` helps control the repeatability of outputs by steering random number generation. Pinning this to a specific value helps us test the changes of other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd92b8b-1161-4ce1-b048-6887ff0e48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "body[\"max_tokens\"] = 1024 \n",
    "body[\"temperature\"] = 0.9  # typical range: 0 -> 1\n",
    "body[\"top_p\"] = 0.9  # typical range: 0 -> 1\n",
    "body[\"seed\"] = 1  # pinned to a constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b32a1-4ada-4f56-84fe-e187789b6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary with selected values\n",
    "summarize_response = vss_api_call(VSS_URL, \"summarize\", verb=\"post\", json=body)\n",
    "print(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b037d65-c33b-4de9-aa1b-2a22e23fea39",
   "metadata": {},
   "source": [
    "## Enable Chat\n",
    "\n",
    "When the model is consistently returning desirable results, the blueprint has been fine tuned. You can now start building your custom application.\n",
    "\n",
    "Before we do that, thought, we need to do one last summarization to enable chat and build the RAG databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b4ee3d-8d73-4abd-8de8-abe572c71eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "body[\"enable_chat\"] = True\n",
    "summarize_response = vss_api_call(VSS_URL, \"summarize\", verb=\"post\", json=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe604f-61db-4fe1-919c-acb382eee398",
   "metadata": {},
   "source": [
    "# ðŸ¥³ Complete\n",
    "\n",
    "The VSS Blueprint has been fully customized. Feel free to save and close this file and return to the workshop instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67e370-28a2-4863-890f-5250b9f167a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ¤“ Extra Credit\n",
    "\n",
    "It's not necessary... yet... but if you wanted to chat with this video, here is a playground. This *might* be useful soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c3b20-c093-4444-b6ad-cf6bd83d5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client = helpers.Chat(\n",
    "    VSS_URL, \n",
    "    video_id=upload_response.get(\"id\"),\n",
    "    model_id=models_response[\"data\"][0][\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689aa04-d024-4e43-964a-241fe367068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client.query(\"What happened in the video?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81273d5b-7a1d-4477-92a3-aa190dde10d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
