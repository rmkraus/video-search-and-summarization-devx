{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8c280c-d44d-4a58-87cf-52b58900b570",
   "metadata": {},
   "source": [
    "# Introduction To Visual Search and Summarization Blueprint\n",
    "\n",
    "In this notebook, we care going to use camera footage from a warehouse to ensure safety policies are being followed.\n",
    "\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33279cd-31bd-4158-9053-80177baa496a",
   "metadata": {},
   "source": [
    "This is some basic imports, settings, and helper functions. No need to make any changes, but feel free to take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643aafcb-6bec-48ed-8ebc-c2affcbea24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "from IPython.display import Markdown, Video\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from typing import Literal, Any\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac5ff1-5f51-40aa-be88-1ee5c6079561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths and locations\n",
    "VSS_URL = \"http://via-server:8100\"\n",
    "WAREHOUSE_VIDEO = Path(\"./assets/warehouse.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587177bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for talking to the API\n",
    "def check_response(response):\n",
    "    \"\"\"Return the proper response.\"\"\"\n",
    "    print(f\"Response Code: {response.status_code}\")\n",
    "    response.raise_for_status()\n",
    "    try:\n",
    "        return response.json()\n",
    "    except requests.exceptions.JSONDecodeError:\n",
    "        return response.text\n",
    "\n",
    "def vss_api_call(\n",
    "        vss_url: str,\n",
    "        target: str,\n",
    "        params: None | dict[str, str] = None,\n",
    "        verb: Literal[\"get\"] | Literal [\"post\"] = \"get\",\n",
    "        json: Any = None,\n",
    "        files: Any = None,\n",
    "        data: Any = None,\n",
    "    ) -> dict[str, Any] | str:\n",
    "    \"\"\"Query the VIA Agent API and handle the response.\"\"\"\n",
    "    # determine the full url\n",
    "    url = urljoin(vss_url, target)\n",
    "\n",
    "    # query the api\n",
    "    if verb == \"get\":\n",
    "        response = requests.get(url, params=params)\n",
    "    elif verb == \"post\":\n",
    "        response = requests.post(url, params=params, json=json, data=data, files=files)\n",
    "    else:\n",
    "        raise ValueError(\"Verb must be either get or post.\")\n",
    "\n",
    "    return check_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92ada9-1738-4e20-b692-934638b5d2a0",
   "metadata": {},
   "source": [
    "## API Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a4c41-dcef-49d2-a5e9-ddce92552599",
   "metadata": {},
   "source": [
    "VSS provides a REST API that operates the blueprint. \n",
    "This API is the integration point for your own custom applications.\n",
    "You can browse the API documentation at http://HOSTNAME:8100/docs. The API actions are split into categories. \n",
    "\n",
    "Today, we are going to focus on:\n",
    "- Health Check\n",
    "- Models\n",
    "- Files\n",
    "- Summarization\n",
    "- Alerts\n",
    "\n",
    "```\n",
    "TODO: route through proxy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c491dbf-0827-474a-a1fe-669c68e91a6f",
   "metadata": {},
   "source": [
    "### Health Checks API\n",
    "\n",
    "Let's first start by checking out the health checks. Typically, these are going to be called your deployment system to check the status of the server, but we can check them here using `curl`.\n",
    "\n",
    "There are two endpoints: a liveness probe and a readiness probe. A liveness probe tells us if the service is working. The readiness probe tells us if the service is ready to handle requests. These probes will return a `200` status if they are healthy and an error status code (`4XX` or `5XX`) if the probe is not healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e335d40-2300-43c2-832b-92128df7f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liveness Probe\n",
    "# Is the service running?\n",
    "! curl -i {VSS_URL}/health/live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43f3ff-7a5f-4aa5-a36f-a5d238b2362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readiness Probe\n",
    "# Is the service ready for requests?\n",
    "! curl -i {VSS_URL}/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f8c91-8b31-4f49-a932-5c17c6824462",
   "metadata": {},
   "source": [
    "### Models API\n",
    "\n",
    "The models endpoint will return the LLM available to use for summarization requests. This is based on the the startup configuration for VSS. This LLM could be configured to point to any OpenAI compatible LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ff46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_response = vss_api_call(VSS_URL, \"models\")\n",
    "\n",
    "models_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc861f",
   "metadata": {},
   "source": [
    "### Files API\n",
    "\n",
    "To start processing a video, it must first be uploaded to VSS. \n",
    "Several endpoints are available to interact with the files. \n",
    "\n",
    "For our first example, we will be using the `WAREHOUSE_VIDEO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(WAREHOUSE_VIDEO, width=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea44fbe",
   "metadata": {},
   "source": [
    "We can upload new videos using the `files` endpoint and the `post` verb.\n",
    "\n",
    "This endpoint requires three inputs:\n",
    "- the file contents\n",
    "- the file's purpose\n",
    "- the file's type\n",
    "\n",
    "When uploading a video for processing, the purpose is `vision` and the type is `video`.\n",
    "\n",
    "To summarize a single image file, a single image could also be uploaded with media_type \"image\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38271d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WAREHOUSE_VIDEO.open(\"rb\") as file:\n",
    "    # setup query data\n",
    "    files = {\"file\": (WAREHOUSE_VIDEO.name, file)}\n",
    "    data = {\"purpose\":\"vision\", \"media_type\":\"video\"}\n",
    "\n",
    "    # query the vss api\n",
    "    upload_response = vss_api_call(\n",
    "        VSS_URL, \n",
    "        \"files\",\n",
    "        verb=\"post\",\n",
    "        files=files,\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845be52",
   "metadata": {},
   "source": [
    "Check out the unique id in the response. That is how we will reference this file going forward.\n",
    "\n",
    "We can also list all of the available files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db287ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vss_api_call(VSS_URL, \"files\", params={\"purpose\":\"vision\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fb392",
   "metadata": {},
   "source": [
    "### Summarization APIs - Summarize\n",
    "\n",
    "Once a video or image has been uploaded, the ```/summarize``` endpoint can be called to generate a summary. \n",
    "\n",
    "In the body of the request, we will include the video ID and model's ID from above. There are also some prompt and model options. We will explore all these options later in the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"id\": upload_response.get(\"id\"),\n",
    "    \"prompt\": \"Write a caption based on the video clip.\",\n",
    "    \"caption_summarization_prompt\": \"Combine sequential captions to create more concise descriptions.\",\n",
    "    \"summary_aggregation_prompt\": \"Write a summary of the video. \",\n",
    "    \"model\": models_response[\"data\"][0][\"id\"],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.8,\n",
    "    \"chunk_duration\": 20,\n",
    "    \"chunk_overlap_duration\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85c232",
   "metadata": {},
   "source": [
    "We can now request a summary. Depending on the video length and configuration options this request may take some time to return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_response = vss_api_call(VSS_URL, \"summarize\", verb=\"post\", json=body)\n",
    "\n",
    "summarize_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c1b64",
   "metadata": {},
   "source": [
    "Let's check out the summary we generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13501543",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\"> \" + summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66860fcf",
   "metadata": {},
   "source": [
    "If everything went perfectly, that answer was pretty basic. Without much context on the situation, and your intentions, the model struggles to extract meaning. In every situation, the summarization prompts will need to be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb2aaef",
   "metadata": {},
   "source": [
    "### Customizing Summarization Prompts \n",
    "\n",
    "The VSS Blueprint processes videos with a four stage pipeline:\n",
    "- **Chunking:** videos are split into windows of a few seconds\n",
    "- **Dense Captioning:** generate descriptions of each window\n",
    "- **Aggregated Captioning:** aggregate dense captions to cover longer windows\n",
    "- **Summarization:** generate a caption that describes all chunks \n",
    "\n",
    "![Summarization Pipeline](./assets/summarization_diagram.png)\n",
    "\n",
    "A set of three prompts are used to control the summary generation through the three stages shown in the diagram. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c4775",
   "metadata": {},
   "source": [
    "`prompt` must include enough information so the model knows what it should be looking for in the video. If the summary is missing important details it is likely becuase the VLM did not extract those details from the video chunks in the first place. \n",
    "\n",
    "Often what works well is a three part prompt: \n",
    "\n",
    "1) Persona \n",
    "2) Details\n",
    "3) Format\n",
    "\n",
    "For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"You are a warehouse monitoring system. \"\n",
    "    \"Describe the events you are seeing. \"\n",
    "    \"In addition to general descriptions, look for: \"\n",
    "    \"policy violations, equipment usage, and restricted areas. \"\n",
    "    \"All employees must wear helmets and vests in the warehouse. \"\n",
    "    \"Employees must not cross yellow safety tape.  \"\n",
    "    \"Start each sentence with start and end timestamp of the event.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b81a3",
   "metadata": {},
   "source": [
    "Often, the text descriptions generated by the VLM can be repetetitive in sequential or overlaping chunks. To condense the VLM captions efficiently, an LLM is used.\n",
    "\n",
    "`caption_summarization_prompt` is the prompt used to instruct this aggragation. This prompt can typically stay the same across use cases as it just needs to instruct the LLM to combine similar descriptions together. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02202007",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_summarization_prompt = (\n",
    "    \"You will be given captions from sequential clips of a video. \"\n",
    "    \"Aggregate captions in the format start_time:end_time:caption \"\n",
    "    \"based on whether captions are related to one another or \"\n",
    "    \"create a continuous scene.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04ef9a",
   "metadata": {},
   "source": [
    "`summary_aggregation_prompt` is used to generate the final summary. It is used in a single LLM call along with all the aggregated captions to generate the summary output. \n",
    "\n",
    "This prompt should reiterate what details need to be included in the summary and any formatting options. Keep in mind that at this stage, the summary can only include details that are present in aggregated captions produced in the previous stage.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48937f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_aggregation_prompt = (\n",
    "    \"Based on the available information, \"\n",
    "    \"generate a summary that captures the important events in the video. \"\n",
    "    \"The summary should be organized chronologically and in logical sections. \"\n",
    "    \"This should be a concise, yet descriptive summary of all the important events. \"\n",
    "    \"The format should be intuitive and easy for a user to read and understand what happened. \"\n",
    "    \"Format the output in Markdown so it can be displayed nicely.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf0bf7",
   "metadata": {},
   "source": [
    "Now that our prompts follow best practices, let's rerun the summarization with `enable_chat` turned on.\n",
    "\n",
    "This instructs the VSS agent to also create a database of video details. We'll talk more about this in the next section. Until then, expect this run to take a bit longer than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"id\": upload_response.get(\"id\"),\n",
    "    \"prompt\": prompt,\n",
    "    \"caption_summarization_prompt\": caption_summarization_prompt,\n",
    "    \"summary_aggregation_prompt\": summary_aggregation_prompt,\n",
    "    \"model\": models_response[\"data\"][0][\"id\"],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.8,\n",
    "    \"seed\": 1,\n",
    "    \"num_frames_per_chunk\": 5,\n",
    "    \"chunk_duration\": 20,\n",
    "    \"chunk_overlap_duration\": 0,\n",
    "    \"enable_chat\": True\n",
    "}\n",
    "\n",
    "summarize_response = vss_api_call(VSS_URL, \"summarize\", verb=\"post\", json=body)\n",
    "\n",
    "summarize_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db726827",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f58eca",
   "metadata": {},
   "source": [
    "Now that's a lot more like it! This is a lot more useful information. \n",
    "Already, we can identify policy violations and should be able to flag them in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4248b",
   "metadata": {},
   "source": [
    "### Summarization APIs - Chat Completions\n",
    "\n",
    "That summary  was great, but there is so much more insight in the video that we haven't used.\n",
    "\n",
    "Part of the blueprint's Summarization APIs is a chat completion endpoint. \n",
    "Chatting with your videos allows you to discover new information without modifying your existing pipelines.\n",
    "Here is a very basic class that will interact with this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06100ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    \"\"\"A simple wrapper to chat with a video.\"\"\"\n",
    "\n",
    "    def __init__(self, vss_url: str, video_id: str, model_id: str):\n",
    "        \"\"\"Initialize the class.\"\"\"\n",
    "        self.vss_url = vss_url\n",
    "        self.video_id = video_id\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def query(self, msg: str):\n",
    "        \"\"\"Chat with the VSS agent.\"\"\"\n",
    "        # format the message\n",
    "        messages = [{\n",
    "            \"content\": msg,\n",
    "            \"role\": \"user\"\n",
    "        }]\n",
    "\n",
    "        # generate request payload\n",
    "        payload = {\n",
    "            \"id\": self.video_id,\n",
    "            \"messages\": messages,\n",
    "            \"model\": self.model_id,\n",
    "        }\n",
    "\n",
    "        # query the vss agent\n",
    "        response_data = vss_api_call(\n",
    "            self.vss_url,\n",
    "            \"chat/completions\",\n",
    "            verb=\"post\",\n",
    "            json=payload\n",
    "        )\n",
    "        answer = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client = Chat(\n",
    "    VSS_URL,\n",
    "    video_id=upload_response.get(\"id\"),\n",
    "    model_id=models_response[\"data\"][0][\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113e858",
   "metadata": {},
   "source": [
    "# Uh oh! \n",
    "\n",
    "ðŸ«¨ **Surprise Audit Today** ðŸ«¨\n",
    "\n",
    "Today we will be doing a new audit of forklift usage.\n",
    "There is a sign-out sheet for the forklift, and we want to ensure it is accurate.\n",
    "Our sign sheet indicates one signout about a minute after this recording started.\n",
    "\n",
    "Because this is a new audit, we have no collected any historical data. \n",
    "However, we can chat with our video library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client.query(\"Did the forklift appear?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client.query(\"When did the forklift first appear?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc56bb",
   "metadata": {},
   "source": [
    "Excellent! We were able to complete the audit quickly. Even better, we were already in compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5ca71",
   "metadata": {},
   "source": [
    "# ðŸ¥³ Complete!\n",
    "\n",
    "Congratulations! We have succewsfully built an intelligent surveilance system.\n",
    "\n",
    "Feel free to save and close this file and return to the workshop instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab3db4-0fb6-451e-8d68-a54035d6e295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
